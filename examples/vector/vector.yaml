data_dir: "/var/lib/vector"

sources:
  kafka_logs:
    type: "kafka"
    bootstrap_servers: "kafka:29092"
    group_id: "vector-logs"
    topics:
      - "logs.application"
    auto_offset_reset: "earliest"
    decoding:
      codec: "json"
      json:
        lossy: true

transforms:
  parse_logs:
    type: "remap"
    inputs:
      - "kafka_logs"
    source: |
      # docker_logs sends the raw line in .message (e.g. "2026-02-25 16:39:57.372 | {\"timestamp\":...}").
      # Extract the JSON part and replace the event with the parsed envelope so labels work.
      json_str = string(.message) ?? ""
      if contains(json_str, " | ") {
        parts = split(json_str, " | ", limit: 2)
        json_str = string(parts[1]) ?? json_str
      }
      parsed, err = parse_json(json_str)
      if err == null && is_object(parsed) {
        . = parsed
      }
      # Extract label values from the structured log envelope
      if is_object(.service) {
        .label_service = string(.service."service.name") ?? "unknown"
        .label_environment = string(.service."deployment.environment") ?? "unknown"
      } else {
        .label_service = string(.service) ?? "unknown"
        .label_environment = string(.environment) ?? "unknown"
      }
      .label_severity = string(.severity) ?? string(.level) ?? "info"

sinks:
  loki:
    type: "loki"
    inputs:
      - "parse_logs"
    endpoint: "http://loki:3100"
    encoding:
      codec: "json"
    labels:
      service: "{{ label_service }}"
      severity: "{{ label_severity }}"
      environment: "{{ label_environment }}"
    remove_label_fields: true
    out_of_order_action: "accept"

api:
  enabled: true
  address: "0.0.0.0:8686"
